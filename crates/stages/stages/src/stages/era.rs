use crate::{stages, StageCheckpoint, StageId};
use alloy_primitives::{BlockHash, BlockNumber};
use futures_util::{Stream, StreamExt};
use reqwest::{Client, Url};
use reth_config::config::EtlConfig;
use reth_db_api::{table::Value, tables, transaction::DbTxMut, DbTxUnwindExt};
use reth_era_downloader::{read_dir, EraClient, EraMeta, EraStream, EraStreamConfig};
use reth_era_utils as era;
use reth_etl::Collector;
use reth_primitives_traits::{Block, FullBlockBody, FullBlockHeader, NodePrimitives};
use reth_provider::{
    BlockHashReader, BlockReader, BlockWriter, DBProvider, HeaderProvider, NodePrimitivesProvider,
    StaticFileProviderFactory, StaticFileWriter, StorageLocation,
};
use reth_stages_api::{ExecInput, ExecOutput, Stage, StageError, UnwindInput, UnwindOutput};
use reth_static_file_types::StaticFileSegment;
use reth_storage_errors::ProviderError;
use std::{
    fmt::{Debug, Formatter},
    fs,
    path::PathBuf,
    task::{ready, Context, Poll},
};

type ThreadSafeEraStream = Box<
    dyn Stream<Item = eyre::Result<Box<dyn EraMeta + Sync + Send + 'static>>>
        + Send
        + Sync
        + 'static
        + Unpin,
>;

/// The [ERA1](https://github.com/eth-clients/e2store-format-specs/blob/main/formats/era1.md)
/// pre-merge history stage.
///
/// Imports block headers and bodies from genesis up to the last pre-merge block. Receipts are
/// generated by execution. Execution is not done in this stage.
pub struct EraStage {
    source: Option<ImportSource>,
    hash_collector: Collector<BlockHash, BlockNumber>,
    item: Option<Box<dyn EraMeta + Sync + Send + 'static>>,
    stream: Option<ThreadSafeEraStream>,
    last_block_height: Option<BlockNumber>,
}

impl Debug for EraStage {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("EraStage")
            .field("source", &self.source)
            .field("hash_collector", &self.hash_collector)
            .field("item", &self.item)
            .field("stream", &"dyn Stream")
            .finish()
    }
}

/// Describes where to get the era files from.
#[derive(Debug, Clone)]
pub enum ImportSource {
    /// Remote HTTP accessible host.
    Url(Url, PathBuf),
    /// Local directory.
    Path(PathBuf),
}

impl EraStage {
    /// Creates a new [`EraStage`].
    pub fn new(source: Option<ImportSource>, etl_config: EtlConfig) -> Self {
        Self {
            source,
            item: None,
            stream: None,
            last_block_height: None,
            hash_collector: Collector::new(etl_config.file_size, etl_config.dir),
        }
    }
}

impl<Provider, B, BB, BH> Stage<Provider> for EraStage
where
    B: Block<Header=BH, Body=BB>,
    BH: FullBlockHeader + Value,
    BB: FullBlockBody<
        Transaction=<<Provider as NodePrimitivesProvider>::Primitives as NodePrimitives>::SignedTx,
        OmmerHeader=BH,
    >,
    Provider: DBProvider<Tx: DbTxMut> + StaticFileProviderFactory + BlockWriter<Block=B> + BlockReader<Block=B>,
    <Provider as NodePrimitivesProvider>::Primitives:
    NodePrimitives<BlockHeader=BH, BlockBody=BB>,
{
    fn id(&self) -> StageId {
        StageId::Era
    }

    fn poll_execute_ready(&mut self, cx: &mut Context<'_>, _input: ExecInput) -> Poll<Result<(), StageError>> {
        if self.stream.is_none() {
            if let Some(source) = self.source.clone() {
                match source {
                    ImportSource::Path(path) => {
                        self.stream.replace({
                            let stream = read_dir(path).map_err(|e| StageError::Fatal(e.into()))?;

                            Box::new(Box::pin(stream
                                .map(|v| v
                                    .map(|v| Box::new(v) as Box<dyn EraMeta + Send + Sync + 'static>))
                            ))
                        });
                    }
                    ImportSource::Url(url, era_dir) => {
                        let folder = era_dir.into_boxed_path();
                        let client = EraClient::new(Client::new(), url, folder);

                        self.stream.replace({
                            let stream = EraStream::new(client, EraStreamConfig::default());

                            Box::new(Box::pin(stream
                                .map(|v| v
                                    .map(|v| Box::new(v) as Box<dyn EraMeta + Send + Sync + 'static>))
                            ))
                        });
                    }
                }
            }
        }
        if let Some(stream) = &mut self.stream {
            if let Some(next) = ready!(stream.poll_next_unpin(cx)).transpose().map_err(|e| StageError::Fatal(e.into()))? {
                self.item.replace(next);
            }
        }

        Poll::Ready(Ok(()))
    }

    fn execute(&mut self, provider: &Provider, input: ExecInput) -> Result<ExecOutput, StageError> {
        Ok(match self.item.take() {
            Some(era) => {
                let static_file_provider = provider.static_file_provider();

                // Consistency check of expected headers in static files vs DB is done on provider::sync_gap
                // when poll_execute_ready is polled.
                let last_header_number = static_file_provider
                    .get_highest_static_file_block(StaticFileSegment::Headers)
                    .unwrap_or_default();

                // Find the latest total difficulty
                let mut td = static_file_provider
                    .header_td_by_number(last_header_number)?
                    .ok_or(ProviderError::TotalDifficultyNotFound(last_header_number))?;

                // Although headers were downloaded in reverse order, the collector iterates it in ascending
                // order
                let mut writer = static_file_provider.latest_writer(StaticFileSegment::Headers)?;

                if let Some(height) = era::process(era.as_ref(), &mut writer, provider, &mut self.hash_collector, &mut td).map_err(|e| StageError::Recoverable(e.into()))? {
                    self.last_block_height.replace(height);
                }

                ExecOutput::in_progress(input.checkpoint())
            }
            None => {
                if self.source.is_some() {
                    era::build_index(provider, &mut self.hash_collector)
                        .map_err(|e| StageError::Recoverable(e.into()))?;
                }

                ExecOutput::done(StageCheckpoint::new(input.target()))
            }
        })
    }

    fn unwind(
        &mut self,
        provider: &Provider,
        input: UnwindInput,
    ) -> Result<UnwindOutput, StageError> {
        self.hash_collector.clear();
        self.item.take();
        self.last_block_height.take();
        self.stream.take();

        if let Some(source) = &self.source {
            // Wipe any unprocessed era files in the download temp directory
            if let ImportSource::Url(_, path) = source {
                if let Ok(dir) = path.read_dir() {
                    for entry in dir.flatten() {
                        let path = entry.path();

                        if path.extension() == Some("era1".as_ref()) {
                            let _ = fs::remove_file(path);
                        }
                    }
                }
            }

            // First unwind the db tables, until the unwind_to block number. use the walker to unwind
            // HeaderNumbers based on the index in CanonicalHeaders
            // unwind from the next block number since the unwind_to block is exclusive
            provider
                .tx_ref()
                .unwind_table_by_walker::<tables::CanonicalHeaders, tables::HeaderNumbers>(
                    (input.unwind_to + 1)..,
                )?;
            provider.tx_ref().unwind_table_by_num::<tables::CanonicalHeaders>(input.unwind_to)?;
            provider
                .tx_ref()
                .unwind_table_by_num::<tables::HeaderTerminalDifficulties>(input.unwind_to)?;

            // determine how many headers to unwind from the static files based on the highest block and
            // the unwind_to block
            let static_file_provider = provider.static_file_provider();
            let highest_block = static_file_provider
                .get_highest_static_file_block(StaticFileSegment::Headers)
                .unwrap_or_default();
            let static_file_headers_to_unwind = highest_block - input.unwind_to;
            for block_number in (input.unwind_to + 1)..=highest_block {
                let hash = static_file_provider.block_hash(block_number)?;
                // we have to delete from HeaderNumbers here as well as in the above unwind, since that
                // mapping contains entries for both headers in the db and headers in static files
                //
                // so if we are unwinding past the lowest block in the db, we have to iterate through
                // the HeaderNumbers entries that we'll delete in static files below
                if let Some(header_hash) = hash {
                    provider.tx_ref().delete::<tables::HeaderNumbers>(header_hash, None)?;
                }
            }

            // Now unwind the static files until the unwind_to block number
            let mut writer = static_file_provider.latest_writer(StaticFileSegment::Headers)?;
            writer.prune_headers(static_file_headers_to_unwind)?;

            // Bodies
            stages::ensure_consistency(provider, Some(input.unwind_to))?;
            provider.remove_bodies_above(input.unwind_to, StorageLocation::Both)?;
        }

        Ok(UnwindOutput { checkpoint: input.checkpoint.with_block_number(input.unwind_to) })
    }
}
